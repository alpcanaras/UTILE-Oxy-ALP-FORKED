{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ea30943-4e2d-436b-871f-5cd841c51d33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/alpcanaras/oxy/bin/python3\n",
      "input path is: /Users/alpcanaras/Desktop/FZJ Thesis General/Utile OXY/TIFF Stacks/Labeled and Cleaned/labeled_cleaned1800mV.tiff\n",
      "output tiff stack will be saved at: /Users/alpcanaras/Desktop/FZJ Thesis General/Utile OXY/TIFF Stacks/Labeled and Cleaned/labeled_cleaned1800mV_tracked_nosplits.tiff\n",
      "output csv file will be saved at: /Users/alpcanaras/Desktop/FZJ Thesis General/Utile OXY/TIFF Stacks/Labeled and Cleaned/labeled_cleaned1800mV_datas_nosplits.csv.\n"
     ]
    }
   ],
   "source": [
    "## just to confirm\n",
    "import sys\n",
    "print(sys.executable)\n",
    "\n",
    "#imports \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from skimage import io\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "import time\n",
    "import re\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "##inputs -change with your own\n",
    "_1500mV_cln='/Users/alpcanaras/Desktop/FZJ Thesis General/Utile OXY/TIFF Stacks/Labeled and Cleaned/labeled_cleaned1500mV.tiff'\n",
    "_1600mV_cln='/Users/alpcanaras/Desktop/FZJ Thesis General/Utile OXY/TIFF Stacks/Labeled and Cleaned/labeled_cleaned1600mV.tiff'\n",
    "_1700mV_cln='/Users/alpcanaras/Desktop/FZJ Thesis General/Utile OXY/TIFF Stacks/Labeled and Cleaned/labeled_cleaned1700mV.tiff'\n",
    "_1800mV_cln='/Users/alpcanaras/Desktop/FZJ Thesis General/Utile OXY/TIFF Stacks/Labeled and Cleaned/labeled_cleaned1800mV.tiff'\n",
    "\n",
    "\n",
    "#just for ease of use and ease of labeling outputs\n",
    "full_path =_1800mV_cln ## CHANGE WITH YOUR OWN PATH\n",
    "\n",
    "output_tiff_stack_path = Path(full_path).parent/ f\"{Path(full_path).stem}_tracked_nosplits.tiff\"\n",
    "combined_csv_path = Path(full_path).parent/ f\"{Path(full_path).stem}_datas_nosplits.csv\"\n",
    "\n",
    "print(f\"\"\"input path is: {full_path}\n",
    "output tiff stack will be saved at: {output_tiff_stack_path}\n",
    "output csv file will be saved at: {combined_csv_path}.\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04297e3f-6320-47a5-8943-226b9ae576b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total frames to process: 15570\n",
      "Processing frames 0 to 499...\n",
      "Processing frames 500 to 999...\n",
      "Processing frames 1000 to 1499...\n",
      "Processing frames 1500 to 1999...\n",
      "Processing frames 2000 to 2499...\n",
      "Processing frames 2500 to 2999...\n",
      "Processing frames 3000 to 3499...\n",
      "Processing frames 3500 to 3999...\n",
      "Processing frames 4000 to 4499...\n",
      "Processing frames 4500 to 4999...\n",
      "Processing frames 5000 to 5499...\n",
      "Processing frames 5500 to 5999...\n",
      "Processing frames 6000 to 6499...\n",
      "Processing frames 6500 to 6999...\n",
      "Processing frames 7000 to 7499...\n",
      "Processing frames 7500 to 7999...\n",
      "Processing frames 8000 to 8499...\n",
      "Processing frames 8500 to 8999...\n",
      "Processing frames 9000 to 9499...\n",
      "Processing frames 9500 to 9999...\n",
      "Processing frames 10000 to 10499...\n",
      "Processing frames 10500 to 10999...\n",
      "Processing frames 11000 to 11499...\n",
      "Processing frames 11500 to 11999...\n",
      "Processing frames 12000 to 12499...\n",
      "Processing frames 12500 to 12999...\n",
      "Processing frames 13000 to 13499...\n",
      "Processing frames 13500 to 13999...\n",
      "Processing frames 14000 to 14499...\n",
      "Processing frames 14500 to 14999...\n",
      "Processing frames 15000 to 15499...\n",
      "Processing frames 15500 to 15569...\n",
      "Processing completed in 961.36 seconds.\n",
      "Combined metrics and coordinates saved to /Users/alpcanaras/Desktop/FZJ Thesis General/Utile OXY/Tunnel Viz November/cleaned1800mV_datas_v2.csv\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import time\n",
    "from collections import defaultdict\n",
    "import tifffile\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import io\n",
    "\n",
    "# ----------------------------\n",
    "# LABEL STORAGE AND GLOBALS\n",
    "# ----------------------------\n",
    "labels_data = []\n",
    "global_instance_counter = 0\n",
    "frame_creation = {}\n",
    "\n",
    "# Initialize global sets for active and inactive labels\n",
    "inactive_labels = set()\n",
    "active_labels = set()\n",
    "\n",
    "# Batch size for processing large TIFF stacks\n",
    "BATCH_SIZE = 500  # Adjust this based on your system's memory capacity 500 is reasonably fast\n",
    "\n",
    "# ----------------------------\n",
    "# LABEL GENERATION FUNCTIONS\n",
    "# ----------------------------\n",
    "def generate_label(instance_counter, frame_number):\n",
    "    \"\"\"Generate a unique label based on instance counter and frame number.\"\"\"\n",
    "    return f\"{instance_counter}_frame{frame_number}\"\n",
    "\n",
    "def generate_merge_label(instance_counter, parent_labels, frame_number):\n",
    "    \"\"\"\n",
    "    Generate a unique label for merged objects following the pattern:\n",
    "    \"{new_instance}_frame{frame_number}_({parent1}+{parent2}+...)\".\n",
    "    Example: \"7_frame2_(3+4)\"\n",
    "    \"\"\"\n",
    "    parents = \"+\".join(parent_labels)\n",
    "    return f\"{instance_counter}_frame{frame_number}_({parents})\"\n",
    "\n",
    "# ----------------------------\n",
    "# IMAGE PROCESSING FUNCTIONS\n",
    "# ----------------------------\n",
    "def preprocess_image_otsu(frame):\n",
    "    \"\"\"Convert frame to grayscale and apply Otsu's thresholding.\"\"\"\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    _, binary = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    return binary\n",
    "\n",
    "def detect_contours(binary_image):\n",
    "    \"\"\"Detect external contours in the binary image.\"\"\"\n",
    "    contours, _ = cv2.findContours(binary_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    return contours\n",
    "\n",
    "def calculate_metrics(img, contour):\n",
    "    \"\"\"Calculate various metrics for a given contour.\"\"\"\n",
    "    area = cv2.contourArea(contour)\n",
    "    equivalent_diameter = np.sqrt(4 * area / np.pi)\n",
    "    _, _, w, h = cv2.boundingRect(contour)\n",
    "    aspect_ratio = float(w) / h if h != 0 else 0\n",
    "    hull = cv2.convexHull(contour)\n",
    "    hull_area = cv2.contourArea(hull)\n",
    "    solidity = float(area) / hull_area if hull_area > 0 else 0\n",
    "    orientation = cv2.fitEllipse(contour)[-1] if len(contour) >= 5 else 0\n",
    "    rect_area = w * h\n",
    "    extent = float(area) / rect_area if rect_area > 0 else 0\n",
    "    perimeter = cv2.arcLength(contour, True)\n",
    "    (x, y), radius = cv2.minEnclosingCircle(contour)\n",
    "    min_circle_area = np.pi * radius * radius\n",
    "    roundness = area / min_circle_area if min_circle_area > 0 else 0\n",
    "    return {\n",
    "        \"area\": area,\n",
    "        \"diameter\": equivalent_diameter,\n",
    "        \"aspect_ratio\": aspect_ratio,\n",
    "        \"solidity\": solidity,\n",
    "        \"orientation\": orientation,\n",
    "        \"extent\": extent,\n",
    "        \"perimeter\": perimeter,\n",
    "        \"roundness\": roundness\n",
    "    }\n",
    "\n",
    "# ----------------------------\n",
    "# SPLIT HANDLING FUNCTIONS\n",
    "# ----------------------------\n",
    "def average_split_centroids(detected_splits):\n",
    "    \"\"\"Average the centroids of split objects to smooth their positions.\"\"\"\n",
    "    for label, data in detected_splits.items():\n",
    "        centroids = data[\"centroids\"]\n",
    "        count = data[\"count\"]\n",
    "        avg_cX = int(sum(x for x, y in centroids) / count)\n",
    "        avg_cY = int(sum(y for x, y in centroids) / count)\n",
    "        \n",
    "        # Update labels_data with averaged centroid for all occurrences of the split label\n",
    "        for entry in labels_data:\n",
    "            if entry[\"label\"] == label:\n",
    "                entry[\"centroid_x\"] = avg_cX\n",
    "                entry[\"centroid_y\"] = avg_cY\n",
    "\n",
    "# ----------------------------\n",
    "# CONTOUR PROCESSING FUNCTION\n",
    "# ----------------------------\n",
    "def process_contour(contour, frame_lab, previous_frame_objects, frame_number, detected_splits, current_frame_label_usage, frame_creation, metrics_dict):\n",
    "    \"\"\"\n",
    "    Process a single contour to assign labels, handle splits, and calculate metrics.\n",
    "    \"\"\"\n",
    "    global global_instance_counter\n",
    "    mask = np.zeros(frame_lab.shape[:2], dtype=np.uint8)\n",
    "    cv2.drawContours(mask, [contour], -1, 255, -1)\n",
    "    M = cv2.moments(contour)\n",
    "    if M[\"m00\"] == 0:\n",
    "        return None\n",
    "    cX = int(M[\"m10\"] / M[\"m00\"])\n",
    "    cY = int(M[\"m01\"] / M[\"m00\"])\n",
    "\n",
    "    overlapping_labels = []\n",
    "    for prev_label, prev_masks in previous_frame_objects.items():\n",
    "        for prev_mask in prev_masks:\n",
    "            if np.logical_and(mask, prev_mask).any():\n",
    "                overlapping_labels.append(prev_label)\n",
    "                break  # Stop after finding an overlap with this label\n",
    "\n",
    "    generated_label = None\n",
    "    if len(overlapping_labels) == 1:\n",
    "        prev_label = overlapping_labels[0]\n",
    "        is_split_product = any(\n",
    "            split_label for split_label in detected_splits.keys() \n",
    "            if split_label == prev_label or \n",
    "               (isinstance(prev_label, str) and prev_label.startswith(split_label.split('_frame')[0]))\n",
    "        )\n",
    "\n",
    "        if current_frame_label_usage[prev_label] > 0:\n",
    "            if prev_label not in detected_splits:\n",
    "                detected_splits[prev_label] = {\n",
    "                    \"centroids\": [(cX, cY)],\n",
    "                    \"count\": 1,\n",
    "                    \"frame_detected\": frame_number\n",
    "                }\n",
    "                inactive_labels.add(prev_label)\n",
    "                active_labels.discard(prev_label)\n",
    "            else:\n",
    "                detected_splits[prev_label][\"centroids\"].append((cX, cY))\n",
    "                detected_splits[prev_label][\"count\"] += 1\n",
    "\n",
    "            generated_label = prev_label\n",
    "            frame_creation[generated_label] = frame_creation.get(prev_label, frame_number)\n",
    "        elif is_split_product:\n",
    "            generated_label = prev_label\n",
    "            frame_creation[generated_label] = frame_creation.get(prev_label, frame_number)\n",
    "        else:\n",
    "            generated_label = prev_label\n",
    "\n",
    "        current_frame_label_usage[prev_label] += 1\n",
    "    elif len(overlapping_labels) > 1:\n",
    "        global_instance_counter += 1\n",
    "        parent_labels = [label.split('_')[0] for label in overlapping_labels]\n",
    "        generated_label = generate_merge_label(global_instance_counter, parent_labels, frame_number)\n",
    "        frame_creation[generated_label] = frame_number\n",
    "        current_frame_label_usage[generated_label] += 1\n",
    "    else:\n",
    "        found_nearby_split = False\n",
    "        for split_label, split_data in detected_splits.items():\n",
    "            if frame_number - split_data.get(\"frame_detected\", 0) <= 2:\n",
    "                for split_centroid in split_data[\"centroids\"]:\n",
    "                    distance = np.sqrt((cX - split_centroid[0])**2 + (cY - split_centroid[1])**2)\n",
    "                    if distance < 50:\n",
    "                        generated_label = split_label\n",
    "                        found_nearby_split = True\n",
    "                        break\n",
    "            if found_nearby_split:\n",
    "                break\n",
    "\n",
    "        if not found_nearby_split:\n",
    "            global_instance_counter += 1\n",
    "            generated_label = generate_label(global_instance_counter, frame_number)\n",
    "            frame_creation[generated_label] = frame_number\n",
    "\n",
    "        current_frame_label_usage[generated_label] += 1\n",
    "\n",
    "    if generated_label not in frame_creation:\n",
    "        frame_creation[generated_label] = frame_number\n",
    "\n",
    "    labels_data.append({\n",
    "        \"label\": generated_label,\n",
    "        \"frame_number\": frame_number,\n",
    "        \"centroid_x\": cX,\n",
    "        \"centroid_y\": cY\n",
    "    })\n",
    "    return {\n",
    "        \"label\": generated_label,\n",
    "        \"mask\": mask,\n",
    "        \"centroid\": (cY, cX),\n",
    "        \"contour\": contour,\n",
    "        \"frame_number\": frame_number\n",
    "    }\n",
    "\n",
    "# ----------------------------\n",
    "# ANNOTATION FUNCTION\n",
    "# ----------------------------\n",
    "def draw_and_annotate_frame(frame, contour_labels):\n",
    "    \"\"\"Draw contours and annotations (labels and centroids) on the frame.\"\"\"\n",
    "    for result in contour_labels:\n",
    "        generated_label = result[\"label\"]\n",
    "        roi = np.zeros_like(frame[:, :, 0])\n",
    "        cv2.drawContours(roi, [result[\"contour\"]], -1, 255, -1)\n",
    "        cv2.circle(frame, (result[\"centroid\"][1], result[\"centroid\"][0]), 2, (255, 0, 0), -1)\n",
    "        cv2.putText(frame, f\"{generated_label}\", (result[\"centroid\"][1] - 50, result[\"centroid\"][0]),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 1, cv2.LINE_AA)\n",
    "        cv2.drawContours(frame, [result[\"contour\"]], -1, (0, 0, 255), 1)\n",
    "    return frame\n",
    "\n",
    "# ----------------------------\n",
    "# FRAME PROCESSING FUNCTION\n",
    "# ----------------------------\n",
    "def process_frame(frame, previous_frame_objects, frame_number, metrics_dict):\n",
    "    \"\"\"\n",
    "    Process a single frame: detect contours, assign labels, calculate metrics, and annotate.\n",
    "    \"\"\"\n",
    "    global frame_creation\n",
    "    global global_instance_counter\n",
    "\n",
    "    if len(frame.shape) == 2 or frame.shape[2] == 1:\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_GRAY2RGB)\n",
    "    if frame.size == 0:\n",
    "        return frame, previous_frame_objects\n",
    "\n",
    "    new_frame_objects = defaultdict(list)\n",
    "    current_frame_label_usage = defaultdict(int)\n",
    "    detected_splits = {}\n",
    "    contour_labels = []\n",
    "\n",
    "    binary_image = preprocess_image_otsu(frame)\n",
    "    contours = detect_contours(binary_image)\n",
    "    frame_lab = cv2.cvtColor(frame, cv2.COLOR_BGR2LAB)\n",
    "\n",
    "    for contour in contours:\n",
    "        result = process_contour(\n",
    "            contour, frame_lab, previous_frame_objects, frame_number,\n",
    "            detected_splits, current_frame_label_usage, frame_creation, metrics_dict\n",
    "        )\n",
    "        if result:\n",
    "            contour_labels.append(result)\n",
    "            label = result[\"label\"]\n",
    "            metrics = calculate_metrics(frame, result[\"contour\"])\n",
    "            for metric, value in metrics.items():\n",
    "                metrics_dict[frame_number][label][metric] = value\n",
    "\n",
    "    average_split_centroids(detected_splits)\n",
    "\n",
    "    frame = draw_and_annotate_frame(frame, contour_labels)\n",
    "\n",
    "    for result in contour_labels:\n",
    "        generated_label = result[\"label\"]\n",
    "        new_frame_objects[generated_label].append(result[\"mask\"])\n",
    "\n",
    "    previous_frame_objects = new_frame_objects\n",
    "\n",
    "    return frame, previous_frame_objects\n",
    "\n",
    "# ----------------------------\n",
    "# MAIN PROCESSING LOOP\n",
    "# ----------------------------\n",
    "metrics_dict = defaultdict(lambda: defaultdict(dict))\n",
    "previous_frame_objects = defaultdict(list)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "with tifffile.TiffFile(full_path) as tif:  # Replace with actual input path\n",
    "    num_frames = len(tif.pages)\n",
    "    print(f\"Total frames to process: {num_frames}\") ## just to confirm\n",
    "\n",
    "    with tifffile.TiffWriter(output_tiff_stack_path, bigtiff=True) as tif_writer:\n",
    "        for batch_start in range(0, num_frames, BATCH_SIZE):\n",
    "            batch_end = min(batch_start + BATCH_SIZE, num_frames)\n",
    "            tiff_stack = tif.asarray(key=range(batch_start, batch_end))\n",
    "\n",
    "            processed_stack = []\n",
    "\n",
    "            for idx, frame in enumerate(tiff_stack):\n",
    "                frame_number = batch_start + idx\n",
    "                processed_frame, previous_frame_objects = process_frame(\n",
    "                    frame, previous_frame_objects, frame_number, metrics_dict\n",
    "                )\n",
    "                processed_stack.append(processed_frame)\n",
    "\n",
    "            for processed_frame in processed_stack:\n",
    "                tif_writer.write(processed_frame.astype(np.uint8))\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Processing completed in {end_time - start_time:.2f} seconds.\") \n",
    "\n",
    "##SAVE CSV ##\n",
    "\n",
    "# Convert labels_data to a dictionary for faster lookups ##NEW VERSION \n",
    "labels_dict = {(item[\"label\"], item[\"frame_number\"]): item for item in labels_data}\n",
    "\n",
    "metrics_rows = []\n",
    "for frame_number, frame_data in metrics_dict.items():\n",
    "    for label, label_data in frame_data.items():\n",
    "        centroid_data = labels_dict.get((label, frame_number), {})\n",
    "        row = {\n",
    "            \"frame_number\": frame_number,\n",
    "            \"label\": label,\n",
    "            \"centroid_x\": centroid_data.get(\"centroid_x\", 0),\n",
    "            \"centroid_y\": centroid_data.get(\"centroid_y\", 0)\n",
    "        }\n",
    "        row.update(label_data)\n",
    "        metrics_rows.append(row)\n",
    "\n",
    "combined_df = pd.DataFrame(metrics_rows)\n",
    "combined_df.fillna(0, inplace=True)\n",
    "combined_df.to_csv(combined_csv_path, index=False)\n",
    "print(f\"Combined metrics and coordinates saved to {combined_csv_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1174198-0c93-498c-ae86-69485d9689eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
